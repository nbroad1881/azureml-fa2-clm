{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from azure.ai.ml import MLClient, command, dsl, Input, Output\n",
    "from azure.ai.ml.entities import Environment, BuildContext, AmlCompute\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "\n",
    "credential = InteractiveBrowserCredential()\n",
    "\n",
    "PATH_TO_CONFIG_FILE = \"./config.json\"\n",
    "\n",
    "ml_client = MLClient.from_config(credential, path=PATH_TO_CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_MAPPING = {\n",
    "    # **Flash attention v2 only works on GPUs that start with A (A10, A100), H (H100), L (L40)**\n",
    "    \"1xA10\": \"Standard_NV36adms_A10_v5\",\n",
    "    \"2xA10\": \"Standard_NV72ads_A10_v5\",\n",
    "    \"8xA100\": \"Standard_ND96amsr_A100_v4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"mistral7b-summarization\"\n",
    "TRAIN_DIR = \"train\"\n",
    "TRAIN_ENV_NAME = \"fa2_train_env\"\n",
    "TRAIN_COMPUTE_NAME = \"fa2_a10\"\n",
    "TRAIN_INSTANCE_TYPE = COMPUTE_MAPPING[\"2xA10\"]\n",
    "TRAIN_DISPLAY_NAME = \"fa2 clm training\"\n",
    "TRAIN_DESCRIPTION = \"Training a causal language model using Flash Attention 2\"\n",
    "\n",
    "DATASTORE_NAME = \"workspaceartifactstore\"\n",
    "\n",
    "NUM_GPUS = 2\n",
    "\n",
    "# YearMonthDayHourMinute\n",
    "timenow = datetime.utcnow().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "TRAINING_OUTPUT_PATH = MODEL_NAME + \"__\" + timenow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_compute_target(\n",
    "    ml_client,\n",
    "    compute_name,\n",
    "    instance_type=\"STANDARD_DS3_v2\",\n",
    "    min_nodes=0,\n",
    "    max_nodes=1,\n",
    "    idle_time=300,\n",
    "):\n",
    "    try:\n",
    "        cmpute = ml_client.compute.get(compute_name)\n",
    "        cmpute_name = cmpute.name\n",
    "    except Exception:\n",
    "        print(f\"Creating a new {instance_type} compute target...\")\n",
    "        compute = AmlCompute(\n",
    "            name=compute_name,\n",
    "            size=instance_type,\n",
    "            min_instances=min_nodes,\n",
    "            max_instances=max_nodes,\n",
    "            idle_time_before_scale_down=idle_time,\n",
    "        )\n",
    "        ml_client.compute.begin_create_or_update(compute)\n",
    "        cmpute_name = compute.name\n",
    "    return cmpute_name\n",
    "\n",
    "\n",
    "def get_environment(\n",
    "    environment_name,\n",
    "    dependencies_dir,\n",
    "    ml_client,\n",
    "    gpu=False,\n",
    "    dep_yaml=None,\n",
    "    dockerfile_path=None,\n",
    "):\n",
    "    try:\n",
    "        env = ml_client.environments.get(name=environment_name)\n",
    "    except Exception:\n",
    "        if gpu:\n",
    "            image = \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04\"\n",
    "        else:\n",
    "            image = \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
    "\n",
    "        if dockerfile_path is not None:\n",
    "            build_context = BuildContext(\n",
    "                path=dependencies_dir, dockerfile_path=dockerfile_path\n",
    "            )\n",
    "\n",
    "            env = Environment(\n",
    "                name=environment_name,\n",
    "                description=\"Custom environment\",\n",
    "                build=build_context,\n",
    "            )\n",
    "        else:\n",
    "            env = Environment(\n",
    "                name=environment_name,\n",
    "                description=\"Custom environment\",\n",
    "                conda_file=os.path.join(dependencies_dir, dep_yaml),\n",
    "                image=image,\n",
    "            )\n",
    "\n",
    "        env = ml_client.environments.create_or_update(env)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_environment = get_environment(\n",
    "    environment_name=TRAIN_ENV_NAME,\n",
    "    dependencies_dir=TRAIN_DIR,\n",
    "    ml_client=ml_client,\n",
    "    gpu=True,\n",
    "    dockerfile_path=\"Dockerfile\",\n",
    ")\n",
    "\n",
    "train_compute = get_or_create_compute_target(\n",
    "    ml_client=ml_client,\n",
    "    compute_name=TRAIN_COMPUTE_NAME,\n",
    "    min_nodes=0,\n",
    "    max_nodes=2,\n",
    "    instance_type=TRAIN_INSTANCE_TYPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_command = command(\n",
    "    name=\"train\",\n",
    "    display_name=TRAIN_DISPLAY_NAME,\n",
    "    inputs={\n",
    "        \"num_gpus\": NUM_GPUS,\n",
    "    },\n",
    "    outputs={\n",
    "        \"output_dir\": Output(\n",
    "            type=\"uri_folder\",\n",
    "            path=f\"azureml://datastores/{DATASTORE_NAME}/paths/{TRAINING_OUTPUT_PATH}\",\n",
    "            mode=\"rw_mount\",\n",
    "        ),\n",
    "    },\n",
    "    # The source folder of the component\n",
    "    code=\"./train\",\n",
    "    command=\"\"\"accelerate launch \\\n",
    "             --num_machines 1 \\\n",
    "             --multi_gpu \\\n",
    "             --num_processes  ${{inputs.num_gpus}} \\\n",
    "                train.py \\\n",
    "                --model_name_or_path \"mistralai/Mistral-7B-v0.1\" \\\n",
    "                --max_seq_length 4096 \\\n",
    "                --evaluation_strategy epoch \\\n",
    "                --save_strategy epoch \\\n",
    "                --save_total_limit 2 \\\n",
    "                --logging_steps 25 \\\n",
    "                --per_device_train_batch_size 8 \\\n",
    "                --per_device_eval_batch_size 8 \\\n",
    "                --learning_rate 1e-4 \\\n",
    "                --num_train_epochs 3 \\\n",
    "                --weight_decay 0.01 \\\n",
    "                --optim paged_adamw_8bit \\\n",
    "                --warmup_ratio 0.05 \\\n",
    "                --bf16 \\\n",
    "                --output_dir ${{outputs.output_dir}} \\\n",
    "                --logging_dir ${{outputs.output_dir}} \\\n",
    "                --dataloader_num_workers 4 \\\n",
    "                --gradient_accumulation_steps 1 \\\n",
    "                --seed 42 \\\n",
    "                --report_to mlflow \\\n",
    "                --attn_implementation \"flash_attention_2\" \\\n",
    "                --num_proc 16 \\\n",
    "                --gradient_checkpointing \\\n",
    "                --ddp_find_unused_parameters False\n",
    "            \"\"\",\n",
    "    environment=f\"{train_environment.name}:{train_environment.version}\",\n",
    "    compute=train_compute,\n",
    "    instance_count=1,\n",
    "    shm_size=\"16g\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    description=TRAIN_DESCRIPTION,\n",
    "    display_name=TRAIN_DISPLAY_NAME,\n",
    ")\n",
    "def pipeline_func():\n",
    "    train_job = train_command()\n",
    "\n",
    "    return {\n",
    "        \"pipeline_job_train_data\": train_job.outputs.output_dir,\n",
    "    }\n",
    "\n",
    "\n",
    "pipeline = pipeline_func()\n",
    "\n",
    "\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=TRAINING_OUTPUT_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
